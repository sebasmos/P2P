{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfd73be2-56f2-466f-858d-b634ce9cbcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_path = \"data\"\n",
    "SAVER = True #False\n",
    "#root = \"/home/sebasmos/Desktop/DATASETS/pix2pix/val\"\n",
    "#root = \"/n/pfister_lab2/Lab/vcg_biology/ORION/ORION-PATCH/C1-C40-patches/CRC06\"\n",
    "#root = \"/net/coxfs01/srv/export/coxfs01/pfister_lab2/share_root/Lab/scajas/DATASETS/DATASET_pix2pix_merged/DATAFULL/train\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf0d160b-7788-454f-955f-867328bed7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_he\timg_if\tmask\n",
      "Celltable_C1.csv\n",
      "Celltable_C1-YC.csv\n",
      "Celltable_C2.csv\n",
      "Celltable_C3.csv\n",
      "Celltable_C40B1.csv\n",
      "Celltable_C40B2.csv\n",
      "Celltable_C4.csv\n",
      "Celltype_OrionCRC_20220211.xlsx\n",
      "P37_S24_Full_A24_C59kX_E15@20220104_223653_988272.ome.tiff\n",
      "P37_S25_Full_A24_C59kX_E15@20220105_001442_622814.ome.tiff\n",
      "P37_S25_Scan_20220114_131907_01x3x00400.rcpnl\n",
      "P37_S26_Lung_A24_C59kX_E15@20220105_224440_730242.ome.tiff\n",
      "P37_S26_NSCLC_A24_C59kX_E15@20220105_001550_901031.ome.tiff\n",
      "P37_S27_Full_A24_C59kX_E15@20220106_002943_210932.ome.tiff\n",
      "P37_S28_A24_C59kX_E15@20220106_014116_878434.ome.tiff\n",
      "P37_S29_A24_C59kX_E15@20220106_014304_946511.ome.tiff\n",
      "P37_S30_A24_C59kX_E15@20220106_014319_409148.ome.tiff\n",
      "P37_S31_A24_C59kX_E15@20220106_014409_014236.ome.tiff\n",
      "P37_S32_A24_C59kX_E15@20220106_014630_553652.ome.tiff\n",
      "P37_S33_A24_C59kX_E15@20220107_180446_881530.ome.tiff\n",
      "P37_S34_A24_C59kX_E15@20220107_202112_212579.ome.tiff\n",
      "P37_S35_A24_C59kX_E15@20220108_012037_490594.ome.tiff\n",
      "P37_S36_A24_C59kX_E15@20220108_012058_082564.ome.tiff\n",
      "P37_S37_A24_C59kX_E15@20220108_012113_953544.ome.tiff\n",
      "P37_S38_A24_C59kX_E15@20220108_012130_664519.ome.tiff\n"
     ]
    }
   ],
   "source": [
    "# CRC01\n",
    "!ls /net/coxfs01/srv/export/coxfs01/pfister_lab2/share_root/Lab/scajas/DATASETS/DATASET_pix2pix/train\n",
    "!ls /n/pfister_lab2/Lab/vcg_biology/ORION/ORION-IF-1\n",
    "\n",
    "full_img = \"/n/pfister_lab2/Lab/vcg_biology/ORION/ORION-IF-1/P37_S34_A24_C59kX_E15\"\n",
    "root = \"/net/coxfs01/srv/export/coxfs01/pfister_lab2/share_root/Lab/scajas/DATASETS/DATASET_pix2pix/train\"\n",
    "save_dir = \"/net/coxfs01/srv/export/coxfs01/pfister_lab2/scajas/pytorch-CycleGAN-and-pix2pix_master/CRC01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "869b74ab-c552-40a5-a9db-b2a0a6a9b263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(root)\n",
    "import copy\n",
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import skimage.exposure\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "\n",
    "\n",
    "#import transforms as T\n",
    "import torchvision.transforms as visionT\n",
    "import pdb\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "import glob\n",
    "\n",
    "import random\n",
    "import tifffile\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "if not os.path.exists(store_path):\n",
    "    os.makedirs(store_path)\n",
    "else:\n",
    "    print('folder already exists')\n",
    "\n",
    "def plot_imgs(imgs, titles):\n",
    "    \"\"\"\n",
    "    Generate visualization of list of arrays\n",
    "    :param imgs: list of arrays, each numpy array is an image of size (width, height)\n",
    "    :param titles: list of titles [string]\n",
    "    \"\"\"\n",
    "    # create figure\n",
    "    fig = plt.figure(figsize=(50, 50))\n",
    "    # loop over images\n",
    "    for i in range(len(imgs)):\n",
    "        fig.add_subplot(4, 4, i + 1)\n",
    "        plt.imshow(imgs[i])\n",
    "        plt.title(str(titles[i]))\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "#import transforms as T # Custom version \n",
    "import PIL\n",
    "import skimage.exposure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ccac6c-3ff1-4ad4-9069-68bcf573e3ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Calculating minimum and Maximum based on UC folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a29c1-d5e7-45d5-9157-faf4a482ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Dataloader_vcg_sizer(torch.utils.data.Dataset): \n",
    "    def __init__(self, root, \n",
    "                 Check_files = False, \n",
    "                 mask_flag=False, \n",
    "                 augment=False, \n",
    "                 transforms_he=None, \n",
    "                 transforms_if=None):\n",
    "        self.root = root\n",
    "        self.Check_files = Check_files\n",
    "        self.augment = augment\n",
    "        self.transforms_he = transforms_he\n",
    "        self.transforms_if = transforms_if\n",
    "        self.mask_flag = mask_flag\n",
    "        self.imgs = list(sorted([logo_name for i, logo_name in enumerate(os.listdir(os.path.join(root, \"img_he\"))) if \".tif\" in logo_name]  \n",
    "))# HE\n",
    "        self.targets = list(sorted([logo_name for i, logo_name in enumerate(os.listdir(os.path.join(root, \"img_if\"))) if \".tif\" in logo_name]  \n",
    "))# IF  \n",
    "        #self.masks = list(sorted([logo_name for i, logo_name in enumerate(os.listdir(os.path.join(root, \"mask\"))) if \".tif\" in \n",
    "    def __getitem__(self, idx):\n",
    "        ## Data paths \n",
    "        # https://syspharm.slack.com/archives/C02SC9VS7AA/p1663364492474239 \n",
    "        img_path = os.path.join(self.root, \"img_he\", self.imgs[idx])        \n",
    "        targets_path = os.path.join(self.root, \"img_if\", self.targets[idx])\n",
    "        #mask_path = os.path.join(self.root, \"mask\", self.targets[idx])\n",
    "        #print(targets_path)\n",
    "        # Read images\n",
    "        img = tifffile.imread(img_path)\n",
    "        target = tifffile.imread(targets_path)#.astype(\"float32\")\n",
    "        target = skimage.util.img_as_float32(target)\n",
    "        # Normalize images\n",
    "        #CHANNELS = (0, 3, 17)\n",
    "        img = np.moveaxis(img, 0, 2)\n",
    "        channels = range(19)#[0,3,17] # visual markers\n",
    "        target = np.array([target[ch,:,:] for ch in channels]).astype(\"float32\")\n",
    "        target = target.transpose(1,2,0)\n",
    "        #target=torch.as_tensor(target.astype(\"float32\"))\n",
    "\n",
    "        #print(target.shape)\n",
    "        \"\"\"\n",
    "        target = np.dstack([\n",
    "            skimage.exposure.rescale_intensity(\n",
    "                target[c],\n",
    "                in_range=(np.percentile(target[c], 1), np.percentile(target[c], 99.9)),\n",
    "                out_range=(0, 1)\n",
    "            ) \n",
    "            for c in CHANNELS\n",
    "        ]).astype(np.float32)\n",
    "        \"\"\"\n",
    "        if self.augment is not None:        \n",
    "            img, target = self.transforms_he(img), self.transforms_if(target)\n",
    "            return img, target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "def get_transform(train, size=256, HE_IF = \"he\"):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        if HE_IF==\"he\":\n",
    "            transforms.append(T.Resize((size,size)))\n",
    "        elif HE_IF==\"if\":\n",
    "            transforms.append(T.Resize((size,size)))\n",
    "        else:\n",
    "            transforms.append(T.Resize((size,size)))\n",
    "        \n",
    "    return T.Compose(transforms)\n",
    "\n",
    "transforms_he =  get_transform(train= True, size=256, HE_IF = \"he\")\n",
    "transforms_if = get_transform(train=True, size=256 , HE_IF = \"if\")\n",
    "\n",
    "dataset_test = Dataloader_vcg_sizer(root, \n",
    "                                    Check_files = False, \n",
    "                                    mask_flag= False, \n",
    "                                    augment=True, \n",
    "                                    transforms_he=transforms_he, \n",
    "                                    transforms_if=transforms_if)\n",
    "\n",
    "print(\"Dataset size: \", len(dataset_test), \"HE-IF pairs\")\n",
    "\n",
    "dataloader = dataset_test \n",
    "num_batches = 0\n",
    "\n",
    "dict_HE = {\"min\": np.ones((3,1)), \"max\":np.zeros((3,1))}\n",
    "\n",
    "\n",
    "def get_minmax(x):\n",
    "    n = x.shape[0]\n",
    "    minimo = np.ones((n,1))\n",
    "    maximo = np.zeros((n,1))\n",
    "    for ch in range(x.shape[0]):\n",
    "            if np.array(x[ch,:,:].min())<minimo[ch,:]:\n",
    "                minimo[ch,:] = x[ch,:,:].min()\n",
    "            if np.array(x[ch,:,:].max())>maximo[ch,:]:\n",
    "                maximo[ch,:] = x[ch,:,:].max()\n",
    "    return minimo, maximo\n",
    "\n",
    "def calculate_minmax(dataloader):\n",
    "    _he_min=0\n",
    "    _he_max=0\n",
    "    _if_min=0\n",
    "    _if_max=0\n",
    "    batches = 0\n",
    "    for idx in range(len(dataloader)):\n",
    "        img, target = dataset_test[idx]\n",
    "        #print(f\"Range for HE]-> [{img.min(), img.max()}] - Shape: [{img.shape}]\")\n",
    "        #print(f\"Range for IF]-> [{target.min(), target.max()}] - Shape: [{target.shape}]\")\n",
    "        minimoHE, maximoHE = get_minmax(img)\n",
    "        minimoIF, maximoIF = get_minmax(target)#target.min(axis=(1,2)), target.max(axis=(1,2))#\n",
    "        _he_min +=minimoHE\n",
    "        _he_max +=maximoHE\n",
    "        _if_min +=minimoIF\n",
    "        _if_max +=maximoIF\n",
    "        batches+=1\n",
    "    return _if_min / batches, _if_max / batches \n",
    "#import json\n",
    "#out_file = open(\"minmax.json\",\"w\")\n",
    "\n",
    "min,max = calculate_minmax(dataloader)\n",
    "print(\"Method 1\".center(60,\"-\"))\n",
    "print(\"IF MAX: \",max.T)\n",
    "print(\"IF MIN: \", min.T )\n",
    "#print(json.dumps(f))\n",
    "#json.dump(f, \"minmax.json\", ident=6)\n",
    "#out_file.close()\n",
    "maximoIF = np.mean([np.array(dataset_test[idx][1]).max(axis=(1,2)) for idx in range(len(dataloader))], axis=0)\n",
    "minIF = np.mean([np.array(dataset_test[idx][1]).min(axis=(1,2)) for idx in range(len(dataloader))], axis=0)\n",
    "print(\"Method 2\".center(60,\"-\"))\n",
    "print(\"IF MAX: \",maximoIF)\n",
    "print(\"IF MIN: \", minIF )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8f5468-83cc-4b5d-99a1-39b3ecb79972",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Calculating minimum based on Percentile and the average image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e507dfd6-2bee-45b0-b330-993a402821c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader_vcg_sizer(torch.utils.data.Dataset): \n",
    "    def __init__(self, root, \n",
    "                 Check_files = False, \n",
    "                 mask_flag=False, \n",
    "                 augment=False, \n",
    "                 transforms_he=None, \n",
    "                 transforms_if=None):\n",
    "        self.root = root\n",
    "        self.Check_files = Check_files\n",
    "        self.augment = augment\n",
    "        self.transforms_he = transforms_he\n",
    "        self.transforms_if = transforms_if\n",
    "        self.mask_flag = mask_flag\n",
    "        self.imgs = list(sorted([logo_name for i, logo_name in enumerate(os.listdir(os.path.join(root, \"img_he\"))) if \".tif\" in logo_name]  \n",
    "))# HE\n",
    "        self.targets = list(sorted([logo_name for i, logo_name in enumerate(os.listdir(os.path.join(root, \"img_if\"))) if \".tif\" in logo_name]  \n",
    "))# IF  \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root, \"img_he\", self.imgs[idx])        \n",
    "        targets_path = os.path.join(self.root, \"img_if\", self.targets[idx])\n",
    "        img = tifffile.imread(img_path)\n",
    "        target = tifffile.imread(targets_path)\n",
    "        #target = skimage.util.img_as_float32(target)\n",
    "        #CHANNELS = (0, 3, 17)\n",
    "        \n",
    "        img = np.moveaxis(img, 0, 2)\n",
    "        channels = range(19)#[0,3,17] # visual markers\n",
    "        target = np.array([target[ch,:,:] for ch in channels])#.astype(\"float32\")\n",
    "        target = target.transpose(1,2,0)\n",
    "        #target=torch.as_tensor(target.astype(\"float32\"))\n",
    "\n",
    "        #print(target.shape)\n",
    "        \"\"\"\n",
    "        target = np.dstack([\n",
    "            skimage.exposure.rescale_intensity(\n",
    "                target[c],\n",
    "                in_range=(np.percentile(target[c], 1), np.percentile(target[c], 99.9)),\n",
    "                out_range=(0, 1)\n",
    "            ) \n",
    "            for c in CHANNELS\n",
    "        ]).astype(np.float32)\n",
    "        \"\"\"\n",
    "        return img, target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "dataset_train = Dataloader_vcg_sizer(root, \n",
    "                                    Check_files = False, \n",
    "                                    mask_flag= False, \n",
    "                                    augment=True, \n",
    "                                    transforms_he=None, \n",
    "                                    transforms_if=None)\n",
    "_,t = dataset_train[0]\n",
    "print(\"dataset_train size: \", len(dataset_train), \"HE-IF pairs\", t.dtype, t.min(), t.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6032cfbe-a6c6-4310-a4ea-6f2aff168898",
   "metadata": {},
   "source": [
    "#### Calculating percentiles batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c78bb2-f477-480d-b1fc-440b71ddd307",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_PERCENTILE = 0.17\n",
    "MAX_PERCENTILE = 99.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20136f92-1220-4611-84ff-242ee08b56f6",
   "metadata": {},
   "source": [
    "Testing calculation with 1 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a4549a-e08f-42c8-9a7c-a7c44f7b503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before log10 \n",
    "# Defininf axis with np.percentile: axis (1,0) returns 19 list element for first axis: x=1, y =0 ?\n",
    "t_min = np.array([np.percentile(dataset_train[idx][1], MIN_PERCENTILE, axis=(1,0)) \n",
    "                       for idx in range(1)])\n",
    "\n",
    "t_max = np.array([np.percentile(dataset_train[idx][1], MAX_PERCENTILE, axis=(1,0)) \n",
    "                       for idx in range(1)])\n",
    "print(\"Before log10\".center(60,\"-\"))\n",
    "print(t_min.shape, t_min.min(), t_max.max()) \n",
    "\n",
    "# After log10 \n",
    "t_min = np.mean([np.percentile(\n",
    "                       np.log10(dataset_train[idx][1], where=(dataset_train[idx][1] != 0)), MIN_PERCENTILE, axis=(1,0)) \n",
    "                       for idx in range(1)], axis = 0)\n",
    "\n",
    "t_max = np.mean([np.percentile(\n",
    "                       np.log10(dataset_train[idx][1], where=(dataset_train[idx][1] != 0)), MAX_PERCENTILE, axis=(1,0)) \n",
    "                       for idx in range(1)], axis = 0)\n",
    "print(\"After log10\".center(60,\"-\"))\n",
    "print(t_min.shape, t_min.min(), t_max.max()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513a7da5-8090-467e-ac4b-748790bef1d3",
   "metadata": {},
   "source": [
    "Calculating percentiles for the entire training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280358f0-90b2-455e-ba5c-48ba686bbadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "# specify lower and upper percentile cutoffs\n",
    "lower_cutoff_log = np.mean([np.percentile(\n",
    "                       np.log10(dataset_train[idx][1], where=(dataset_train[idx][1] != 0)), MIN_PERCENTILE, axis=(1,0)).ravel() \n",
    "                       for idx in range(len(dataset_train))], axis = 0\n",
    "       )\n",
    "upper_cutoff_log = np.mean([np.percentile(\n",
    "                       np.log10(dataset_train[idx][1], where=(dataset_train[idx][1] != 0)), MAX_PERCENTILE, axis=(1,0)).ravel()\n",
    "                       for idx in range(len(dataset_train))], axis = 0\n",
    "       )\n",
    "total_time = time.time() - start_time\n",
    "print(\"total processing time: \", total_time)                                  \n",
    "assert lower_cutoff_log.shape == upper_cutoff_log.shape\n",
    "print(lower_cutoff_log, upper_cutoff_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a475fee2-f7f8-404a-a37a-0b4f7922909d",
   "metadata": {},
   "source": [
    "Since we do not have the WSI but only the patches, I compute the mean of above all patches using comprenhension lists. \n",
    "Then apply log10 and verify the array values, which are rescaled back to ~0-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54c30d5-24d6-4d47-bb75-745b4080e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_original = np.mean([dataset_train[idx][1] for idx in range(len(dataset_train))], axis = 0)\n",
    "print(\"Mean IF img_original over all dataloader: \", img_original.shape, \"Min value: \",  img_original.min(),\"Max Value: \", img_original.max())\n",
    "log_img_original = np.log10(img_original, where=(img_original != 0))\n",
    "print(\"Mean IF log_img_original over all dataloader: \", log_img_original.shape, \"Min value: \",  log_img_original.min(),\"Max Value: \", log_img_original.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255c7029-2ea7-47aa-a71f-c82ddd985001",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([dataset_train[idx][1] for idx in range(len(dataset_train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa390f05-b666-4c52-9d40-1d0607e134c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "marker = ['Hoechst','AF1','CD31','CD45','CD68','Blank','CD4',\n",
    "          'FOXP3','CD8a','CD45RO','CD20','PD-L1','CD3e','CD163',\n",
    "          'E-Cadherin','PD-1','Ki-67','Pan-CK','SMA'\n",
    "         ]\n",
    "# format plot grid\n",
    "numRows = 4\n",
    "numColumns = 6\n",
    "grid_dims = (numRows, numColumns)\n",
    "# initialize figure canvas\n",
    "fig_orig = plt.figure(figsize=(12, 8.5))\n",
    "fig_log = plt.figure(figsize=(12, 8.5))\n",
    "fig_clip = plt.figure(figsize=(12, 8.5))\n",
    "\n",
    "cutoffs = {}\n",
    "for e, marker_name in enumerate(marker):\n",
    "    # add channel cutoffs to dict\n",
    "    cutoffs[marker_name]=(lower_cutoff_log[e], upper_cutoff_log[e])\n",
    "    # scale 0.17th and 99.99th percentile between 0 and 1\n",
    "    # Note: this will cause outlier pixels below the 0.17th percentile and above\n",
    "    # the 99.99th to take values <0 and >1, respectively\n",
    "    img = img_original[:,:,e]\n",
    "    log_img = log_img_original[:,:,e]\n",
    "    rescaled_log_img = (\n",
    "        (((1-0)*(log_img.ravel()-lower_cutoff_log[e])) /\n",
    "         (upper_cutoff_log[e]-lower_cutoff_log[e])\n",
    "         ) + 0).reshape(log_img.shape)\n",
    "    \n",
    "    # clip outliers to lower and upper percentile cutoffs (i.e., 0-1)\n",
    "    clip_rescaled_log_img = np.clip(a=rescaled_log_img, a_min=0, a_max=1)\n",
    "    \n",
    "    # add channel subplot to figures\n",
    "    ax_orig = fig_orig.add_subplot(grid_dims[0], grid_dims[1], e + 1)\n",
    "    ax_log = fig_log.add_subplot(grid_dims[0], grid_dims[1], e + 1)\n",
    "    ax_clip = fig_clip.add_subplot(grid_dims[0], grid_dims[1], e + 1)\n",
    "    fig_orig.tight_layout() #**ADDING**: vertical padding\n",
    "    fig_log.tight_layout() #**ADDING**: vertical padding\n",
    "\n",
    "    # plot original channel histogram\n",
    "    vals, bins, patches = ax_orig.hist(\n",
    "        img.ravel(), bins=60, color='tab:blue', alpha=0.7, rwidth=0.85\n",
    "        )\n",
    "    ax_orig.title.set_text(marker_name)\n",
    "    \n",
    "    # plot log-transformed channel histogram\n",
    "    vals, bins, patches = ax_log.hist(\n",
    "        log_img.ravel(), bins=60, color='tab:blue', alpha=0.7, rwidth=0.85\n",
    "        )\n",
    "    ax_log.vlines(\n",
    "        x=[np.percentile(log_img.ravel(), 0.17),\n",
    "           np.percentile(log_img.ravel(), 99.99)],\n",
    "        ymin=0, ymax=vals.max(), color='tab:red'\n",
    "           )\n",
    "    ax_log.title.set_text(marker_name)\n",
    "    # plot normalized channel histogram\n",
    "    vals, bins, patches = ax_clip.hist(\n",
    "        clip_rescaled_log_img.ravel(), bins=60,\n",
    "        color='tab:blue', alpha=0.7, rwidth=0.85\n",
    "        )\n",
    "    ax_clip.title.set_text(marker_name)#**ADDING**: vertical padding\n",
    "    \n",
    "plt.xticks(fontsize=5)\n",
    "plt.yticks(fontsize=5)\n",
    "plt.subplots_adjust(bottom=0.9, top=0.99, left=0.01, right=0.99, hspace=10, )\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig_orig.savefig(os.path.join(save_dir, 'log_hists_orig.pdf'))\n",
    "fig_log.savefig(os.path.join(save_dir, 'log_hists_log.pdf'))\n",
    "fig_clip.savefig(os.path.join(save_dir, 'log_hists_clip.pdf'))\n",
    "plt.close('all')\n",
    "\n",
    "# save cutoffs to disk\n",
    "with open(os.path.join(save_dir, 'cutoffs.pkl'), 'wb') as handle:\n",
    "    pickle.dump(cutoffs, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411dcd1a-7ba1-4e6a-ab69-353e3d67fb5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Calculating minimum based on Percentile and the WSI\n",
    "\n",
    "https://github.com/Yu-AnChen/orion-ml-meeting-notes/blob/main/20220916/file_vars.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f7b666f-c6f9-40f8-98cd-7cbd1d99f7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Celltable_C1.csv\n",
      "Celltable_C1-YC.csv\n",
      "Celltable_C2.csv\n",
      "Celltable_C3.csv\n",
      "Celltable_C40B1.csv\n",
      "Celltable_C40B2.csv\n",
      "Celltable_C4.csv\n",
      "Celltype_OrionCRC_20220211.xlsx\n",
      "P37_S24_Full_A24_C59kX_E15@20220104_223653_988272.ome.tiff\n",
      "P37_S25_Full_A24_C59kX_E15@20220105_001442_622814.ome.tiff\n",
      "P37_S25_Scan_20220114_131907_01x3x00400.rcpnl\n",
      "P37_S26_Lung_A24_C59kX_E15@20220105_224440_730242.ome.tiff\n",
      "P37_S26_NSCLC_A24_C59kX_E15@20220105_001550_901031.ome.tiff\n",
      "P37_S27_Full_A24_C59kX_E15@20220106_002943_210932.ome.tiff\n",
      "P37_S28_A24_C59kX_E15@20220106_014116_878434.ome.tiff\n",
      "P37_S29_A24_C59kX_E15@20220106_014304_946511.ome.tiff\n",
      "P37_S30_A24_C59kX_E15@20220106_014319_409148.ome.tiff\n",
      "P37_S31_A24_C59kX_E15@20220106_014409_014236.ome.tiff\n",
      "P37_S32_A24_C59kX_E15@20220106_014630_553652.ome.tiff\n",
      "P37_S33_A24_C59kX_E15@20220107_180446_881530.ome.tiff\n",
      "P37_S34_A24_C59kX_E15@20220107_202112_212579.ome.tiff\n",
      "P37_S35_A24_C59kX_E15@20220108_012037_490594.ome.tiff\n",
      "P37_S36_A24_C59kX_E15@20220108_012058_082564.ome.tiff\n",
      "P37_S37_A24_C59kX_E15@20220108_012113_953544.ome.tiff\n",
      "P37_S38_A24_C59kX_E15@20220108_012130_664519.ome.tiff\n"
     ]
    }
   ],
   "source": [
    "MIN_PERCENTILE = 0.17\n",
    "MAX_PERCENTILE = 99.9#99.99\n",
    "\n",
    "# CRC01\n",
    "full_img = \"/n/pfister_lab2/Lab/vcg_biology/ORION/ORION-IF-1/P37_S34_A24_C59kX_E15@20220107_202112_212579.ome.tiff\"\n",
    "root = \"/net/coxfs01/srv/export/coxfs01/pfister_lab2/share_root/Lab/scajas/DATASETS/DATASET_pix2pix/train\"\n",
    "!ls /n/pfister_lab2/Lab/vcg_biology/ORION/ORION-IF-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff54134f-efd2-4007-8f82-d95e548ba69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IF img_original over all dataloader:  (53770, 64422) Min value:  0 Max Value:  62173\n",
      "Mean IF log_img over all dataloader:  (53770, 64422) Min value:  0.0 Max Value:  4.793602\n"
     ]
    }
   ],
   "source": [
    "from tifffile import imread\n",
    "\n",
    "marker = ['Hoechst','AF1','CD31','CD45','CD68','Blank','CD4',\n",
    "          'FOXP3','CD8a','CD45RO','CD20','PD-L1','CD3e','CD163',\n",
    "          'E-Cadherin','PD-1','Ki-67','Pan-CK','SMA'\n",
    "         ]\n",
    "\n",
    "# save directory\n",
    "save_dir = \"/net/coxfs01/srv/export/coxfs01/pfister_lab2/share_root/Lab/scajas/pytorch-CycleGAN-and-pix2pix_master/CRC01_distributions_title_fixed\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "# format plot grid\n",
    "numRows = 4\n",
    "numColumns = 6\n",
    "grid_dims = (numRows, numColumns)\n",
    "# initialize figure canvas\n",
    "fig_orig = plt.figure(figsize=(12, 8.5))\n",
    "fig_log = plt.figure(figsize=(12, 8.5))\n",
    "fig_clip = plt.figure(figsize=(12, 8.5))\n",
    "\n",
    "cutoffs = {}\n",
    "for e, marker_name in enumerate(marker):\n",
    "    # add channel cutoffs to dict\n",
    "    #cutoffs[marker_name]=(lower_cutoff_log[e], upper_cutoff_log[e])\n",
    "    # scale 0.17th and 99.99th percentile between 0 and 1\n",
    "    # Note: this will cause outlier pixels below the 0.17th percentile and above\n",
    "    # the 99.99th to take values <0 and >1, respectively\n",
    "    # Read channel\n",
    "    img = imread(full_img, key=e)\n",
    "    #img =img_original[:,:,e] \n",
    "    print(\"Mean IF img_original over all dataloader: \", img.shape, \"Min value: \",  img.min(),\"Max Value: \", img.max())\n",
    "    # log-transform image\n",
    "    log_img = np.log10(img, where=(img != 0))\n",
    "    print(\"Mean IF log_img over all dataloader: \", log_img.shape, \"Min value: \",  log_img.min(),\"Max Value: \", log_img.max())\n",
    "    # specify lower and upper percentile cutoffs\n",
    "    lower_cutoff_log = np.percentile(log_img.ravel(), 0.17)\n",
    "    upper_cutoff_log = np.percentile(log_img.ravel(), 99.99)\n",
    "    \n",
    "    # add channel cutoffs to dict\n",
    "    cutoffs[marker_name] = (lower_cutoff_log, upper_cutoff_log)\n",
    "    \n",
    "    # scale 0.17th and 99.99th percentile between 0 and 1\n",
    "    # Note: this will cause outlier pixels below the 0.17th percentile and above\n",
    "    # the 99.99th to take values <0 and >1, respectively\n",
    "    rescaled_log_img = (\n",
    "        (((1-0)*(log_img.ravel()-lower_cutoff_log)) /\n",
    "         (upper_cutoff_log-lower_cutoff_log)\n",
    "         ) + 0).reshape(log_img.shape)\n",
    "\n",
    "    #rescaled_log_img = (\n",
    "    #    (((1-0)*(log_img.ravel()-lower_cutoff_log[e])) /\n",
    "    #     (upper_cutoff_log[e]-lower_cutoff_log[e])\n",
    "    #     ) + 0).reshape(log_img.shape)\n",
    "    \n",
    "    # clip outliers to lower and upper percentile cutoffs (i.e., 0-1)\n",
    "    clip_rescaled_log_img = np.clip(a=rescaled_log_img, a_min=0, a_max=1)\n",
    "    \n",
    "    # add channel subplot to figures\n",
    "    ax_orig = fig_orig.add_subplot(grid_dims[0], grid_dims[1], e + 1)\n",
    "    ax_log = fig_log.add_subplot(grid_dims[0], grid_dims[1], e + 1)\n",
    "    ax_clip = fig_clip.add_subplot(grid_dims[0], grid_dims[1], e + 1)\n",
    "    fig_orig.tight_layout() #**ADDING**: vertical padding\n",
    "    fig_log.tight_layout() #**ADDING**: vertical padding\n",
    "\n",
    "    # plot original channel histogram\n",
    "    vals, bins, patches = ax_orig.hist(\n",
    "        img.ravel(), bins=60, color='tab:blue', alpha=0.7, rwidth=0.85\n",
    "        )\n",
    "    ax_orig.title.set_text(marker_name)\n",
    "\n",
    "    # plot log-transformed channel histogram\n",
    "    vals, bins, patches = ax_log.hist(\n",
    "        log_img.ravel(), bins=60, color='tab:blue', alpha=0.7, rwidth=0.85\n",
    "        )\n",
    "    ax_log.vlines(\n",
    "        x=[np.percentile(log_img.ravel(), 0.17),\n",
    "           np.percentile(log_img.ravel(), 99.99)],\n",
    "        ymin=0, ymax=vals.max(), color='tab:red'\n",
    "           )\n",
    "    ax_log.title.set_text(marker_name)\n",
    "\n",
    "    # plot normalized channel histogram\n",
    "    vals, bins, patches = ax_clip.hist(\n",
    "        clip_rescaled_log_img.ravel(), bins=60,\n",
    "        color='tab:blue', alpha=0.7, rwidth=0.85\n",
    "        )\n",
    "    ax_clip.title.set_text(marker_name)\n",
    "\n",
    "plt.xticks(fontsize=7)\n",
    "plt.yticks(fontsize=7)\n",
    "plt.subplots_adjust(bottom=0.01, top=0.99, left=0.01, right=0.99, hspace=0.2)\n",
    "plt.tight_layout()\n",
    "fig_orig.savefig(os.path.join(save_dir, 'log_hists_orig.pdf'))\n",
    "fig_log.savefig(os.path.join(save_dir, 'log_hists_log.pdf'))\n",
    "fig_clip.savefig(os.path.join(save_dir, 'log_hists_clip.pdf'))\n",
    "plt.close('all')\n",
    "\n",
    "# save cutoffs to disk\n",
    "with open(os.path.join(save_dir, 'cutoffs.pkl'), 'wb') as handle:\n",
    "    pickle.dump(cutoffs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2cfbf-6aa6-47b0-952f-49cce67f11aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /n/pfister_lab2/Lab/vcg_biology/ORION/ORION-PATCH/C1-C40-patches\n",
    "!ls /n/pfister_lab2/Lab/vcg_biology/ORION/\n",
    "#!ls /n/pfister_lab2/Lab/vcg_biology/ORION/ORION-PATCH/C1-C40-patches\n",
    "P37_S34_A24_C59kX_E15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab133aa0-093f-4148-be69-a7abe2584a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /n/pfister_lab2/Lab/vcg_biology/ORION/ORION-IF-4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sebasmos",
   "language": "python",
   "name": "sebasmos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
